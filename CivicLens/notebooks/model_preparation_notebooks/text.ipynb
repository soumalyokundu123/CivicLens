{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdeec04-f080-4d09-b801-e770dc711495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e5af9-5e78-4959-9fe8-a11713643484",
   "metadata": {},
   "source": [
    "# civic_issues_dataset_gpt2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5fd814-b1f0-4d2a-a85c-f142f31c5131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded. Training with 24000 samples, testing with 6000 samples.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. LOAD AND PREPARE THE DATA ---\n",
    "print(\"Loading dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv('civic_issues_dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'civic_issues_dataset.csv' not found.\")\n",
    "    print(\"Please run the 'generate_issues.py' script first to create the dataset.\")\n",
    "    exit()\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = df['Description']\n",
    "y = df[['Category', 'Issue', 'Severity']]\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Dataset loaded. Training with {len(X_train)} samples, testing with {len(X_test)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955c126d-2f4b-474c-83d4-cc8781665751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing text descriptions using TF-IDF...\n",
      "Text vectorization complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. VECTORIZE THE TEXT DATA ---\n",
    "print(\"\\nVectorizing text descriptions using TF-IDF...\")\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "# It will learn the vocabulary from the training data and convert text to a matrix of TF-IDF features.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on the training data and transform it\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only transform the test data using the already fitted vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(\"Text vectorization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9593db9b-d04d-4ff8-bd31-40275fda6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Multi-Output Classifier...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. TRAIN THE MULTI-OUTPUT CLASSIFICATION MODEL ---\n",
    "print(\"\\nTraining the Multi-Output Classifier...\")\n",
    "# We use Logistic Regression as the base estimator. It's fast and works well for text classification.\n",
    "# MultiOutputClassifier will train one LogisticRegression classifier per target column ('Category', 'Issue', 'Severity').\n",
    "base_classifier = LogisticRegression(solver='saga', penalty='l1', C=1.0, random_state=42)\n",
    "multi_output_classifier = MultiOutputClassifier(estimator=base_classifier, n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "multi_output_classifier.fit(X_train_tfidf, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86b607c-db83-403a-9630-19a9a37a6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the test set...\n",
      "\n",
      "--- Classification Report for 'Category' ---\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "     Public Infrastructure       1.00      1.00      1.00       969\n",
      "             Public Safety       1.00      1.00      1.00      1033\n",
      "            Road & Traffic       1.00      1.00      1.00       978\n",
      "Streetlights & Electricity       1.00      1.00      1.00      1024\n",
      "        Waste & Sanitation       1.00      1.00      1.00       950\n",
      "   Water Supply & Drainage       1.00      1.00      1.00      1046\n",
      "\n",
      "                  accuracy                           1.00      6000\n",
      "                 macro avg       1.00      1.00      1.00      6000\n",
      "              weighted avg       1.00      1.00      1.00      6000\n",
      "\n",
      "\n",
      "--- Classification Report for 'Issue' ---\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "        broken streetlights       1.00      1.00      1.00       235\n",
      "     broken traffic signals       1.00      1.00      1.00       231\n",
      "            damaged benches       1.00      1.00      1.00       330\n",
      "          damaged bus stops       1.00      1.00      1.00       290\n",
      "          damaged footpaths       1.00      1.00      1.00       349\n",
      "              damaged roads       1.00      1.00      1.00       246\n",
      "           dim streetlights       1.00      1.00      1.00       255\n",
      "       dirty public toilets       1.00      1.00      1.00       300\n",
      "          drainage overflow       1.00      1.00      1.00       268\n",
      "              exposed wires       1.00      1.00      1.00       281\n",
      "               fallen poles       1.00      1.00      1.00       253\n",
      "            illegal parking       1.00      1.00      1.00       260\n",
      "     missing manhole covers       1.00      1.00      1.00       341\n",
      "              open manholes       1.00      1.00      1.00       355\n",
      "           overflowing bins       1.00      1.00      1.00       316\n",
      "            pipeline bursts       1.00      1.00      1.00       261\n",
      "             pipeline leaks       1.00      1.00      1.00       256\n",
      "       potholes on the road       1.00      1.00      1.00       241\n",
      "        uncollected garbage       1.00      1.00      1.00       334\n",
      "unsafe pedestrian crossings       1.00      1.00      1.00       337\n",
      "               waterlogging       1.00      1.00      1.00       261\n",
      "\n",
      "                   accuracy                           1.00      6000\n",
      "                  macro avg       1.00      1.00      1.00      6000\n",
      "               weighted avg       1.00      1.00      1.00      6000\n",
      "\n",
      "\n",
      "--- Classification Report for 'Severity' ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    critical       0.12      0.03      0.05       671\n",
      "   dangerous       0.10      0.07      0.08       633\n",
      "     growing       0.10      0.11      0.10       650\n",
      "   hazardous       0.13      0.13      0.13       687\n",
      "       major       0.10      0.13      0.11       683\n",
      "       minor       0.11      0.09      0.10       649\n",
      "      severe       0.09      0.07      0.08       657\n",
      " significant       0.10      0.11      0.10       696\n",
      "      slight       0.12      0.22      0.16       674\n",
      "\n",
      "    accuracy                           0.11      6000\n",
      "   macro avg       0.11      0.11      0.10      6000\n",
      "weighted avg       0.11      0.11      0.10      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. EVALUATE THE MODEL ---\n",
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "y_pred = multi_output_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Convert predictions back to a DataFrame for easier evaluation\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=y_test.columns, index=y_test.index)\n",
    "\n",
    "# Print classification report for each target variable\n",
    "print(\"\\n--- Classification Report for 'Category' ---\")\n",
    "print(classification_report(y_test['Category'], y_pred_df['Category']))\n",
    "\n",
    "print(\"\\n--- Classification Report for 'Issue' ---\")\n",
    "print(classification_report(y_test['Issue'], y_pred_df['Issue']))\n",
    "\n",
    "print(\"\\n--- Classification Report for 'Severity' ---\")\n",
    "print(classification_report(y_test['Severity'], y_pred_df['Severity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88eeb1ca-352e-4953-81b2-85c7324e6a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the trained model and vectorizer to disk...\n",
      "âœ… Model and vectorizer saved successfully as 'civic_issue_model.pkl' and 'tfidf_vectorizer.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. SAVE THE MODEL AND VECTORIZER ---\n",
    "print(\"\\nSaving the trained model and vectorizer to disk...\")\n",
    "joblib.dump(multi_output_classifier, 'civic_issue_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "print(\"Model and vectorizer saved successfully as 'civic_issue_model.pkl' and 'tfidf_vectorizer.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1152e2-77ba-4ac3-a0cf-e1033067c667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Prediction ---\n",
      "Input Description: 'Large potholes on the highway intersection have already caused multiple accidents.'\n",
      "\n",
      "Predicted Output:\n",
      "  - Category: Road & Traffic\n",
      "  - Issue: potholes on the road\n",
      "  - Severity: significant\n"
     ]
    }
   ],
   "source": [
    "# --- 6. EXAMPLE PREDICTION ON NEW DATA ---\n",
    "print(\"\\n--- Example Prediction ---\")\n",
    "# Load the model and vectorizer (simulating a real-world application)\n",
    "loaded_model = joblib.load('civic_issue_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Example new description\n",
    "new_description = \"Large potholes on the highway intersection have already caused multiple accidents.\"\n",
    "\n",
    "# Vectorize the new description using the loaded vectorizer\n",
    "new_description_tfidf = loaded_vectorizer.transform([new_description])\n",
    "\n",
    "# Make a prediction\n",
    "prediction = loaded_model.predict(new_description_tfidf)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Input Description: '{new_description}'\")\n",
    "print(\"\\nPredicted Output:\")\n",
    "print(f\"  - Category: {prediction[0][0]}\")\n",
    "print(f\"  - Issue: {prediction[0][1]}\")\n",
    "print(f\"  - Severity: {prediction[0][2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f5073-68d6-4915-bd73-29c71689a0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c3d98-6b2f-45d4-ac2f-f42a01ac171c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
